{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff59d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
    "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.utils import plot_model\n",
    "# from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import librosa.display\n",
    "import librosa as librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.activations import relu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de81a4",
   "metadata": {},
   "source": [
    "1. create train, validation, and test sets\n",
    "\n",
    "2. build the CNN net \n",
    "\n",
    "3. compile the network\n",
    "\n",
    "4. train the CNN\n",
    "\n",
    "5. evaluate the CNN on the test set\n",
    "\n",
    "6. make prediction on a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0162ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with  hip-hop !\n",
      "done with  classical !\n",
      "done with  country !\n",
      "done with  electronic !\n",
      "done with  metal !\n"
     ]
    }
   ],
   "source": [
    "genres = ['hip-hop', 'classical', 'country', 'electronic', 'metal']\n",
    "\n",
    "audio_files_path = '/home/aqeelali7/Documents/Galvanized/Capstone-2-Music-Genre-Classifier/data/'\n",
    "img_save_path = '/home/aqeelali7/Documents/Galvanized/Capstone-2-Music-Genre-Classifier/data/images/'\n",
    "\n",
    "# count = 1\n",
    "\n",
    "X = []\n",
    "target = []\n",
    "hip_hop_dummies = [1, 0, 0, 0, 0]\n",
    "classical_dummies = [0, 1, 0, 0, 0]\n",
    "country_dummies = [0, 0, 1, 0, 0]\n",
    "electronic_dummies = [0, 0, 0, 1, 0]\n",
    "metal_dummies = [0, 0, 0, 0, 1]\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    \n",
    "    new_path = os.path.join(audio_files_path,genres[i])\n",
    "    os.chdir(new_path)\n",
    "    \n",
    "    for track_num in range(len(os.listdir()[:5])):\n",
    "    \n",
    "        \n",
    "        window_size = 256\n",
    "        window = np.hanning(window_size)    \n",
    "        y, sr = librosa.load((os.listdir()[track_num]), duration = 30.0)\n",
    "        stft  = librosa.core.spectrum.stft(y, n_fft=window_size, hop_length=512, window=window)\n",
    "        out = 2 * np.abs(stft) / np.sum(window)\n",
    "        \n",
    "#         X.append(librosa.amplitude_to_db(out, ref=np.max))\n",
    "        \n",
    "        X.append(np.resize(librosa.amplitude_to_db(out, ref=np.max),(513,1292)))\n",
    "           \n",
    "        \n",
    "        if genres[i] == \"hip-hop\":\n",
    "            target.append(hip_hop_dummies)\n",
    "        if genres[i] == \"classical\":\n",
    "            target.append(classical_dummies)\n",
    "        if genres[i] == \"country\":\n",
    "            target.append(country_dummies)\n",
    "        if genres[i] == \"electronic\":\n",
    "            target.append(electronic_dummies)\n",
    "        if genres[i] == \"metal\":\n",
    "            target.append(metal_dummies)\n",
    "            \n",
    "    print('done with ', genres[i],\"!\")\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7002fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-80.       , -49.81893  , -44.737064 , ...,  -7.173379 ,\n",
       "         -17.442698 ,  -8.468687 ],\n",
       "        [-80.       , -39.190617 , -36.844563 , ...,  -7.495792 ,\n",
       "         -13.790283 ,  -8.059917 ],\n",
       "        [-80.       , -32.029533 , -20.059072 , ..., -11.523697 ,\n",
       "         -32.800198 , -13.714672 ],\n",
       "        ...,\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ]],\n",
       "\n",
       "       [[-80.       , -80.       , -14.215791 , ..., -78.17917  ,\n",
       "         -72.90201  , -80.       ],\n",
       "        [-80.       , -80.       ,  -5.2960157, ..., -52.54428  ,\n",
       "         -57.090538 , -57.240593 ],\n",
       "        [-80.       , -80.       ,  -5.015179 , ..., -43.91121  ,\n",
       "         -47.26467  , -44.330383 ],\n",
       "        ...,\n",
       "        [-80.       , -80.       , -80.       , ..., -75.681564 ,\n",
       "         -79.736694 , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ]],\n",
       "\n",
       "       [[-80.       , -32.463024 ,  -7.3861074, ..., -14.993627 ,\n",
       "         -17.720547 , -15.795066 ],\n",
       "        [-80.       , -13.504304 ,  -4.161242 , ..., -14.56043  ,\n",
       "         -15.843984 , -19.048513 ],\n",
       "        [-80.       ,  -9.399053 ,  -7.620182 , ..., -17.440643 ,\n",
       "         -18.19041  , -28.217474 ],\n",
       "        ...,\n",
       "        [-80.       , -47.13937  , -42.705227 , ..., -43.63051  ,\n",
       "         -53.95186  , -65.946724 ],\n",
       "        [-80.       , -53.10333  , -48.91628  , ..., -51.89162  ,\n",
       "         -68.59562  , -66.704544 ],\n",
       "        [-80.       , -71.75026  , -74.3675   , ..., -59.46414  ,\n",
       "         -80.       , -69.338844 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-80.       , -80.       , -80.       , ..., -19.795929 ,\n",
       "         -20.700264 , -20.961082 ],\n",
       "        [-25.704536 , -23.515585 , -15.46846  , ..., -22.114305 ,\n",
       "         -30.01188  , -29.346457 ],\n",
       "        [-24.616701 , -27.639904 , -26.53955  , ..., -35.94596  ,\n",
       "         -35.450493 , -35.656803 ],\n",
       "        ...,\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -60.784634 , ..., -79.14345  ,\n",
       "         -80.       , -74.51718  ]],\n",
       "\n",
       "       [[-80.       , -80.       , -80.       , ..., -30.049988 ,\n",
       "         -21.504627 , -22.985786 ],\n",
       "        [-80.       , -80.       , -80.       , ..., -17.649578 ,\n",
       "         -16.78103  , -16.741852 ],\n",
       "        [-80.       , -80.       , -80.       , ..., -19.280148 ,\n",
       "         -17.9581   , -16.293245 ],\n",
       "        ...,\n",
       "        [-80.       , -80.       , -80.       , ..., -73.305214 ,\n",
       "         -73.04776  , -78.49547  ],\n",
       "        [-80.       , -80.       , -80.       , ..., -78.10414  ,\n",
       "         -80.       , -80.       ],\n",
       "        [-80.       , -80.       , -80.       , ..., -80.       ,\n",
       "         -80.       , -80.       ]],\n",
       "\n",
       "       [[-80.       , -80.       , -76.97769  , ..., -29.702011 ,\n",
       "         -32.499847 , -34.387413 ],\n",
       "        [-40.063313 , -51.013443 , -49.1552   , ..., -31.763882 ,\n",
       "         -14.557295 , -20.98692  ],\n",
       "        [-26.529388 , -22.947828 , -30.8653   , ..., -77.05958  ,\n",
       "         -75.116264 , -76.19594  ],\n",
       "        ...,\n",
       "        [-42.769688 , -43.523396 , -47.88029  , ..., -51.582897 ,\n",
       "         -43.36177  , -60.30175  ],\n",
       "        [-65.13421  , -45.711704 , -38.03628  , ..., -71.16499  ,\n",
       "         -74.04444  , -80.       ],\n",
       "        [-80.       , -80.       , -49.274937 , ..., -40.577465 ,\n",
       "         -27.928068 , -44.641766 ]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "target = np.array(target)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd603032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.20)\n",
    "\n",
    "# X_training_set, X_val, y_training_set, y_val = train_test_split(X_train, y_train, test_size = 0.25)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5\n",
    "\n",
    "# metrics = [metrics.CategoricalAccuracy(name='accuracy')]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe18e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 513, 1292)\n",
      "(5, 513, 1292)\n",
      "(20, 513, 1292, 1)\n",
      "(5, 513, 1292, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = X_train.reshape(-1,513, 1292,1)\n",
    "\n",
    "X_test = X_test.reshape(-1, 513, 1292,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc900e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "testing_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "training_data = training_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "testing_data = testing_data.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09409de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test,target,X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8cfacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 9s 2s/step - loss: 6268.6748 - accuracy: 0.1500 - val_loss: 1254.3533 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 9s 2s/step - loss: 3804.9771 - accuracy: 0.2000 - val_loss: 1714.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 7s 2s/step - loss: 699.1172 - accuracy: 0.3000 - val_loss: 116.3952 - val_accuracy: 0.4000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 141.4377 - accuracy: 0.2500 - val_loss: 68.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 7s 2s/step - loss: 31.0398 - accuracy: 0.4500 - val_loss: 16.1844 - val_accuracy: 0.2000\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 16.1844 - accuracy: 0.2000\n",
      "Test loss: 16.184423446655273\n",
      "Test accuracy: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(513, 1292,1)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_data,\n",
    "          batch_size=8,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=testing_data)\n",
    "\n",
    "score = model.evaluate(testing_data, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# print('Test precision:', score[2])\n",
    "# print('Test recall:', score[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad8fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)  # almost always use shuffle=True\n",
    "fold_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d9f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb3116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd62b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \"\"\"Generates CNN model\n",
    "    :param input_shape (tuple): Shape of input set\n",
    "    :return model: CNN model\n",
    "    \"\"\"\n",
    "\n",
    "    # build network topology\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
